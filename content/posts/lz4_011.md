+++
title = "lz4_flex 0.11: Gainzzzzz Unleashed!"
date = 2023-06-17
keywords = [ "compression", "performance", "lz4" ]
[taxonomies]
categories = [ ]
tags = [ "compression" ]
+++

[lz4_flex](https://github.com/pseitz/lz4_flex) 0.11 has been unleashed, and since the sole purpose of this blog is memes, I'll summarize the performance gainnzzzz as:

{{ embeddover9000(class="testo") }}

I mean look at all the z in gainnzzzz. It has to be really fast.

# Benchmarks

## Setup

AMD Ryzen 7 5900HX, rustc 1.69.0 (84c898d65 2023-04-16), Manjaro, CPU Boost Disabled, CPU: 3Ghz

Tests can be run on the [lz4_flex](https://github.com/pseitz/lz4_flex) repository with `cargo bench`.

{% info() %}
lz4_flex `0.10` and before had a feature-flag `checked-decode` to do additional checks to avoid out-of-bounds access.
`0.11` inverted this feature-flag to `unchecked-decode`. In the benchmarks below all tests are done with out-of-bounds checks.
{% end %}

## Block Format

The graph illustrates a comparison between versions v0.11 and v0.10, and the C90 reference implementation. The lz4_flex crate has two configuration variants:

* no suffix: contains `unsafe`.
* `safe` suffix: contains no `unsafe`.
The block format is ideal for small data up to several megabytes.


{{ embeddblockdecompsvg(class="testo") }}

{{ embeddblockcompsvg(class="testo") }}

## Frame Format
The frame format is suitable for streaming, it consists of concatenated blocks. Blocks in the frame format can be independent or linked for higher compression.

{{ embeddframedecompsvg(class="testo") }}
{{ embeddframecompsvg(class="testo") }}


# Performance Improvements

I regularly get the question what makes lz4_flex so fast. 
There's no simple answer to that, but I can give some insights into the performance improvements of v0.11.
Maybe you can apply the insights to your own code.

### Custom memcpy
Calls to `memcpy` are replaced with a custom memcpy implementation, similar to the wildcopy of 16 bytes.
The function also employs a double copy trick to reduce the number of instructions the CPU has to execute.
Check it out here: [https://github.com/PSeitz/lz4_flex/blob/main/src/fastcpy.rs](https://github.com/PSeitz/lz4_flex/blob/main/src/fastcpy.rs)

- PR: [#113](https://github.com/PSeitz/lz4_flex/pull/113), [#112](https://github.com/PSeitz/lz4_flex/pull/112)
### Optimize Wildcopy
The initial check in the 16-byte wild copy is unnecessary since it is already done before calling the method. Likely irrelevant for performance, but in general: avoid unnecessary work.
- PR: [#109](https://github.com/PSeitz/lz4_flex/pull/109)

### Faster duplicate_overlapping
Replace the aggressive compiler unrolling after the failed attempt [#69](https://github.com/PSeitz/lz4_flex/pull/69) (wrote out of bounds in some cases). 
The compiler will unroll/auto-vectorize a simple byte-by-byte copy with a lot of branches. This is not what we want, as large overlapping copies are not that common.
The unrolling is avoided by manually unrolling with a less aggressive version. Decompression performance is slightly improved by ca 4%, except for the smallest test case.

- PR: [#114](https://github.com/PSeitz/lz4_flex/pull/114)
### Simplify extend_from_within_overlapping

`extend_from_within_overlapping` is used in safe decompression when overlapping data has been detected. 
The prev version had an unnecessary assertion, since this does not hoist the bounds checks. Removing the temporary `&mut` slice also simplifies the resulting assembly.

uiCA Code Analyzer:

| Variant     |  Skylake | IceLake | Tiger Lake | Rocket Lake |
|-------------|----------|---------|------------|-------------|
| uiCA Cycles Prev          | 28.71   | 30.67   | 28.71      | 27.57       |
| uiCA Cycles Simplified  | 13.00   | 15.00   | 13.00      | 11.00       |

- PR: [#72](https://github.com/PSeitz/lz4_flex/pull/72)
### Improve Safe Decompression Performance 8-18%
- PR: [#73](https://github.com/PSeitz/lz4_flex/pull/73)

Reduce multiple slice fetches: every slice access, also nested ones, carries some overhead. In the hot loop, a fixed &[u8;16] is fetched to operate on. This is purely done to pass that info to the compiler. Remove error handling that only carries overhead. As we are in safe mode, we can rely on bounds checks if custom error handling only adds overhead. In normal operation, no error should occur.

The strategy to identify improvements was by counting the lines of assembly. A rough heuristic, but seems effective.

### Improve Safe Frame Compression Performance 7-15%
- PR: [#74](https://github.com/PSeitz/lz4_flex/pull/74)

The frame encoding uses a fixed size hashtable. By creating a special hashtable with a Box<[u32; 4096]> size, in combination with the bit shift of 4, which is also moved into a constant, the compiler can remove the bounds checks. For that to happen, the compiler also needs to recognize the `>> 48` right shift from the hash algorithm (u64 >> 52 <= 4096), which is the case. Yey. It also means we can use less `unsafe` for the unsafe version.

### Switch To Use Only 3 Kinds Of Hashtable
- PR: [#77](https://github.com/PSeitz/lz4_flex/pull/77)

Use only hashtables with fixed sizes and bit shifts that allow removing bounds checks.

# Why is the safe variant slower?  ðŸ˜¤ðŸ˜¤ðŸ˜¤ 

The safe variant's performance has significantly improved due to ongoing effort and compiler optimizations. 
It is still lagging behind though and there's only a few reasons for that:

1. **Bounds checks**:
Each slice access in the safe variant requires bounds checks, if they can't be elided. The `unsafe` variant can avoid them using `get_unchecked` or similar. 
It can be difficult to convince the compiler to eliminate bounds checks.

2. **slice_index_order**:
Do you know bounds checks evil twin brother `slice_index_order`?
For any slice access with addition the compiler has to assume that value may wrap causing index order failure.

```rust
data[pos..pos + 10] // bounds check + slice_index_order check
```

{% info() %}
`slice_index_order` checks can be avoided by proving to the compiler the value can't wrap, e.g.
`pos_u32 as usize + 10` 
{% end %}

3. **LLVM Assembly**:
If the safe version suffers from the presence of bounds checks, it limits the optimizations the compiler can perform without altering the logic.
Reordering the code can't be done if it reorders a bounds check and therefore a potentional panic.
Additionally, there are cases where LLVM generates suboptimal assembly code, further impacting performance. 
I think the reason for that is that the rust compiler generates a lot of llvm IR.

An example regarding bounds checks is a [loop](https://github.com/PSeitz/lz4_flex/blob/main/src/sink.rs#L191-L195) where hoisting was unable to be performed, resulting in two bounds
checks per iteration for every byte copied. That's a lot of overhead.

```rust
pub fn extend_from_within_overlapping(output: &mut [u8], pos: &mut usize, start: usize, num_bytes: usize) {
    let offset = *pos - start;
    for i in start + offset..start + offset + num_bytes {
        output[i] = output[i - offset]; // Two bounds checks
    }
    *pos += num_bytes;
}
```
So if you are up for the challenge to try to remove the bounds checks, it's all ready for you:
[https://godbolt.org/z/bscqYModz](https://godbolt.org/z/bscqYModz)

# New Features

- Allow to pass buffer larger than size [#78](https://github.com/PSeitz/lz4_flex/pull/78).
This removes an unnecessary check in the decompression, when the passed buffer is too big.
- Add auto_finish to FrameEncoder [#95](https://github.com/PSeitz/lz4_flex/pull/95) [#100](https://github.com/PSeitz/lz4_flex/pull/100).
Empty input was ignored previously and didn't write anything. Now an empty Frame is written. This improves compatibility with the reference implementation and some corner cases.
- Autodetect frame blocksize [#81](https://github.com/PSeitz/lz4_flex/pull/81).
The default blocksize of FrameInfo is now auto instead of 64kb, it will detect the blocksize
depending of the size of the first write call. This increases
compression ratio and speed for use cases where the data is larger than
64kb.
- Add fluent API style contruction for FrameInfo [#99](https://github.com/PSeitz/lz4_flex/pull/99) (thanks @CosmicHorrorDev).
This adds in fluent API style construction for FrameInfo. Now you can do
let info = FrameInfo::new()
    .block_size(BlockSize::Max1MB)
    .content_checksum(true);
- Handle empty input [#120](https://github.com/PSeitz/lz4_flex/pull/120).
Empty input was ignored previously and didn't write anything. Now an empty Frame is written. This improves compatibility with the reference implementation and some corner cases.
